import os
import time
import threading
import pandas as pd
import requests
from bs4 import BeautifulSoup
from fpdf import FPDF
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
import streamlit as st

# Chemins des fichiers
excel_file = 'Equipement_Annexe.xlsx'
result_file = 'resultat.xlsx'
stop_file = 'stop_scraping.txt'

# Paramètres de l'email
receiver_emails = ["queenonzlsh@gmail.com", "iliashadaf11@gmail.com"]
smtp_server = 'smtp.gmail.com'
smtp_port = 587
sender_email = "hanae.ouazouneidrissi@gmail.com"
sender_password = "duda bhpx wprs seun"

# Créer le fichier d'équipement s'il n'existe pas
if not os.path.exists(excel_file):
    df = pd.DataFrame(columns=['Marque', 'Modèle', 'Description'])
    df.to_excel(excel_file, index=False)

df = pd.read_excel(excel_file)

# Créer le fichier de résultats s'il n'existe pas
if not os.path.exists(result_file):
    result_df = pd.DataFrame(columns=['Marque', 'Modèle', 'CVE', 'Date de Publication', 'Source'])
    result_df.to_excel(result_file, index=False)

result_df = pd.read_excel(result_file)

# Variable de contrôle pour le scraping
scraping_active = False

# Fonction de scraping et d'envoi d'email
def perform_scraping_and_saving():
    global scraping_active
    scraping_active = True
    
    while scraping_active:
        print("Démarrage du scraping...")
        
        df = pd.read_excel(excel_file)
        items_with_details = []

        for index, row in df.iterrows():
            description = row['Description']
            if pd.notna(description) and isinstance(description, str):
                print(f"Scraping description: {description}")
                scrap_result = scrap(description)
                if scrap_result:
                    items_with_details.append(scrap_result)
        
        # Sauvegarder les résultats dans un fichier Excel
        df_resultats = pd.DataFrame(items_with_details, columns=['Description', 'CVE_ID', 'CVE_URL', 'Published_Date', 'Updated_Date', 'Source'])
        df_resultats.to_excel("resultat.xlsx", index=False)

        # Générer le PDF et envoyer l'email
        pdf_file_path = generate_pdf("resultat.xlsx", "items.json")
        send_email(pdf_file_path)

        # Attendre 5 heures (18000 secondes)
        time.sleep(18000)

    print("Le scraping a été arrêté.")

# Fonction de scraping simplifiée
def scrap(description):
    search_query = description.replace(' ', '+')
    url = f"https://www.cvedetails.com/vulnerability-list.php?search={search_query}"
    
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    cve_identifier = "CVE-2007-5168"
    cve_url = "https://www.cvedetails.com/cve/CVE-2007-5168/?q=CVE-2007-5168"
    published_date = "N/A"
    updated_date = "N/A"
    source = "N/A"

    return [description, cve_identifier, cve_url, published_date, updated_date, source]

# Générer le PDF
def generate_pdf(excel_file, json_file):
    pdf_file = "cve_report.pdf"
    df = pd.read_excel(excel_file)

    pdf = FPDF()
    pdf.add_page()
    
    pdf.image("C:/Users/hp/Desktop/CVE/cve.png", 10, 8, 33)  # Utilisez le chemin absolu
    pdf.image("C:/Users/hp/Desktop/CVE/hcplogo.png", 150, 8, 33)  # Ajout du logo HCP

    pdf.set_font("Arial", size=12)
    pdf.ln(50)

    for index, row in df.iterrows():
        line = f"Description: {row['Description']}, CVE_ID: {row['CVE_ID']}, CVE_URL: {row['CVE_URL']}"
        pdf.cell(200, 10, txt=line, ln=True, align='L')

    pdf.output(pdf_file)
    return pdf_file

# Envoi d'email avec le rapport PDF
def send_email(pdf_file_path):
    msg = MIMEMultipart()
    msg['From'] = sender_email
    msg['To'] = ", ".join(receiver_emails)
    msg['Subject'] = 'CVE Report Sender'

    body = 'Please find the attached CVE report.'
    msg.attach(MIMEText(body, 'plain'))

    attachment = open(pdf_file_path, 'rb')
    part = MIMEBase('application', 'octet-stream')
    part.set_payload(attachment.read())
    encoders.encode_base64(part)
    part.add_header('Content-Disposition', f'attachment; filename={pdf_file_path}')
    msg.attach(part)
    attachment.close()

    try:
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        print('Email sent successfully!')
    except Exception as e:
        print(f'Error: {e}')
    finally:
        server.quit()

    os.remove(pdf_file_path)

# Arrêter le scraping
def stop_scraping():
    global scraping_active
    scraping_active = False
    print("Le scraping a été demandé d'arrêter.")

# Interface Streamlit
st.title("Gestion des équipements et du scraping")

action = st.radio("Choisissez une action", [
    "Ajouter",
    "Supprimer",
    "Modifier",
    "Afficher l'historique des recherches",
    "Démarrer le scraping",
    "Arrêter le scraping"
])

if action == "Ajouter":
    marque = st.text_input("Marque du périphérique")
    modele = st.text_input("Modèle du périphérique")
    description = st.text_area("Description du périphérique")
    if st.button("Ajouter périphérique"):
        if marque and modele and description:
            new_data = pd.DataFrame([{
                "Marque": marque,
                "Modèle": modele,
                "Description": description
            }])
            df = pd.concat([df, new_data], ignore_index=True)
            df.to_excel(excel_file, index=False)
            st.success(f"Périphérique '{modele}' ajouté avec succès !")

elif action == "Supprimer":
    modele_to_delete = st.text_input("Modèle du périphérique à supprimer")
    if st.button("Supprimer périphérique"):
        if modele_to_delete in df['Modèle'].values:
            df = df[df['Modèle'] != modele_to_delete]
            df.to_excel(excel_file, index=False)
            st.success(f"Périphérique '{modele_to_delete}' supprimé avec succès !")

elif action == "Modifier":
    modele_to_modify = st.text_input("Modèle du périphérique à modifier")
    new_marque = st.text_input("Nouvelle marque du périphérique")
    new_modele = st.text_input("Nouveau modèle du périphérique")
    new_description = st.text_area("Nouvelle description")
    if st.button("Modifier périphérique"):
        if modele_to_modify in df['Modèle'].values:
            df.loc[df['Modèle'] == modele_to_modify, ['Marque', 'Modèle', 'Description']] = [new_marque, new_modele, new_description]
            df.to_excel(excel_file, index=False)
            st.success(f"Périphérique '{modele_to_modify}' modifié !")

elif action == "Afficher l'historique des recherches":
    st.subheader("Historique des recherches CVE")
    st.dataframe(result_df)

elif action == "Démarrer le scraping":
    if st.button("Démarrer le scraping"):
        st.write("Le scraping a commencé.")
        threading.Thread(target=perform_scraping_and_saving, daemon=True).start()

elif action == "Arrêter le scraping":
    if st.button("Arrêter le scraping"):
        stop_scraping()
        st.write("Le scraping a été demandé d'arrêter.")
